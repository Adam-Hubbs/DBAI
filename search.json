[{"path":"https://adam-hubbs.github.io/DBAI/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 DBAI authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Adam Hubbs. Author, maintainer.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hubbs (2024). DBAI: AI Tools R Datasets. R package version 0.0.0.9012, https://adam-hubbs.github.io/DBAI/, https://github.com/Adam-Hubbs/DBAI.","code":"@Manual{,   title = {DBAI: AI Tools for R Datasets},   author = {Adam Hubbs},   year = {2024},   note = {R package version 0.0.0.9012, https://adam-hubbs.github.io/DBAI/},   url = {https://github.com/Adam-Hubbs/DBAI}, }"},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"dbai","dir":"","previous_headings":"","what":"AI Tools for R Datasets","title":"AI Tools for R Datasets","text":"DBAI package using AI tools R datasets. can use call AI models straight R without knowledge API’s. can useful sentiment analysis, imputing missing data, creating synthetic data, making predictions . DBAI supports following companies models Open AI via gpt() Popular models include gpt-3.5, gpt-4, gpt-4o Access models behind ChatGPT Anthropic via claude() versions claude3 Google via gemini() Gemini 1.5 family models addition, models can accessed prefered alias function llm_generate(). models can called using similar syntax. main difference four companies require API Key. API Key similar ID Credit Card number companies. use authenticate really making request, track usage bill . API Keys obtained model provider’s website. https://platform.openai.com/playground https://www.anthropic.com/api https://ai.google.dev/gemini-api","code":""},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"costs","dir":"","previous_headings":"","what":"Costs","title":"AI Tools for R Datasets","text":"companies provide reasonable access models. cost changes frequently, accurate place go gauge price website companies directly. typically provide cost per 1 Million tokens (roughly equivalent syllable word). datasets 10,000 rows cost pennies.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"rate-limits","dir":"","previous_headings":"","what":"Rate Limits","title":"AI Tools for R Datasets","text":"Rate limits restrictions many API calls can make given period time. Usually, measured Requests Per Minute. can thought many observations/rows can use function minute stops working. companies work , rate limits start low limit 3-15 per minute free/cheapest options. Rate limits increase money put file provider. Usually $50 $100 get rate limits large enough datasets. get rate limited middle function call save everything done point tell stopped. can rerun function repair=TRUE keep going left .","code":""},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"loading-the-package","dir":"","previous_headings":"","what":"Loading the Package","title":"AI Tools for R Datasets","text":"DBAI hosted github. can install packages github using pak::pak() function. equivalent installing package CRAN using install.packages(), needs done . load package memory, use library() function package CRAN. one step must using package. need set API Key. need set information environmental variable R package can recognize . needs done per R session. need API Key model provider want use. example, care access Claude models need Anthropic API Key. want run OpenAI’s models need OpenAI API Key, etc.","code":"remotes::install_github(\"Adam-Hubbs/DBAI\") library(DBAI) Sys.setenv(   OPENAI_API_KEY = 'XXXXXXXXXXX' )  Sys.setenv(   ANTHROPIC_API_KEY = 'XXXXXXXXXXXX' )  Sys.setenv(   GOOGLE_API_KEY = 'XXXXXXXXXXXX' )"},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"example-data","dir":"","previous_headings":"","what":"Example Data","title":"AI Tools for R Datasets","text":"Let’s input example data use function. ’ll start dataset containing demographic information. age, gender, occupation, location, race, religion information individuals. example, taken information condensed text form column called ‘demo’. See glue package automate . Let’s take information try predict voted 2020 presidential election. dataset prompt, lets call function. call function llm_generate() tell source data “sample_df”, column data want processed called “demo”. want spit results column called “Vote”, prompt using “prompt”, model “gpt-3.5-turbo”. Go ahead run examine results. default, DBAI family models returns list class ‘llm_completion’. first item list returned Data frame new column results. returns prompt, model, model provider, date ran , final object containing miscellaneous meta-data specific provider. llm_completion objects provide way track various meta-data. can also omit information just return dataframe directly without additional information. set return_invisible = TRUE. DBAI functions vectorized can take multiple prompts time return multiple results. Let’s extend first example. , ask predict Vote choice, also predict Party affiliation respondents. made minor changes function call. time pass vector outputs vector prompts. run chunk now get two columns data. Lets take look argument options. discuss four common parameters Large Language Models, temperature, top_p, top_k, max_tokens. first three parameters ways change deterministic random response ., last deals long response . Temperature specifies repetitive analytical , creative random responses . models, temperature runs 0 (Analytical) 2 (Creative). Setting temperature low can lead exact results many calls, regardless data. can also hyper-sensitive examples prompt. Setting temperature high can lead LLM hallucinate make things aren’t real. default, temperature 1, happy medium. may want play around temperature suit specific needs. Top_p top_k sampling methods LLM uses. order understand , let’s take brief refresher Large Language Models work first place. LLM’s work predicting next token (roughly analogous syllable word) sequence. trained virtually written history. Let’s take sentence: man sat next . LLM try predict next word. many possibilities come next, LLM knows , produces probabilities word come next. Let’s say predicts, along ’s respective probability. Note, purely hypothetical. see likely next word ‘Wife’ many options. Top_k restricts sample top K number options. example, top_k set 3 example, LLM choose ‘Wife’, ‘Dog’, ‘Son’. Top_p similarly restricts sample instead giving fixed number options, gives fixed probability. top_p set .5, ‘Wife’ ‘Dog’ considered represent least number options needed reach least .5 probability. Lets say LLM ended choosing ‘Wife’. Lets look word wife another example difference top_k top_p. Maybe next word ‘Wife’ little harder determine 12 words combined together reached .5 probability. case using top_p method 12 words options LLM. Using top_k method still top 3 considered. advised use temperature, top_p, top_k time. models let won’t. Unless really , recommend changing temperature. Max_tokens determines long maximum response . models count input output tokens one, count output tokens. Setting max_tokens low number like 5 restrict response couple words leaving max_tokens blank setting large number like 4,000 enable LLM respond paragraphs analysis.","code":"sample_df <- data.frame(   year = c(1964, 1998, 1979, 1981),   gender = c(\"Male\", \"Female\", \"Male\", \"Female\"),   occupation = c(\"Farmer\", \"Investment Banker\", \"Lawyer\", \"Social Worker\"),   location = c(\"Kansas\", \"New York\", \"Phoenix\", \"Baltimore\"),   race = c(\"White\", \"White\", \"Hispanic\", \"Black\"),   religion = c(\"Evangelical Protestant\", \"Catholic\", \"Catholic\", \"Muslim\"),   demo = c(     \"60 year old white man from Kansas. Is an evangelical protestant and a farmer.\",     \"26 year old white female investment banker from New York. Is a Catholic.\",     \"45 year old male lawyer from Phoenix. Is a hispanic catholic.\",     \"43 year old black female. Works as a social worker in Baltimore and is a practicing muslim.\"))            prompt <- \"I will give you demographic information. I want you to predict who they voted for in the 2020 Presidential election. Make your best guess if you are unsure. Say 'Trump' or 'Biden' only. Do not say anything else.\" return_obj <- llm_generate(source = sample_df, input = \"demo\", output = \"Vote\", prompt = prompt, model = c(\"gpt-3.5-turbo\", \"gemini-1.5-flash\"), max_tokens = 10)  print(return_obj) result_df <- gpt(source = sample_df, input = \"demo\", output = \"Vote\", prompt = prompt, model = \"gpt-3.5-turbo\", return_invisible = TRUE)  print(result_df) sample_df <- data.frame(   year = c(1964, 1998, 1979, 1981),   gender = c(\"Male\", \"Female\", \"Male\", \"Female\"),   occupation = c(\"Farmer\", \"Investment Banker\", \"Lawyer\", \"Social Worker\"),   location = c(\"Kansas\", \"New York\", \"Phoenix\", \"Baltimore\"),   race = c(\"White\", \"White\", \"Hispanic\", \"Black\"),   religion = c(\"Evangelical Protestant\", \"Catholic\", \"Catholic\", \"Muslim\"),   demo = c(     \"60 year old white man from Kansas. Is an evangelical protestant and a farmer.\",     \"26 year old white female investment banker from New York. Is a Catholic.\",     \"45 year old male lawyer from Phoenix. Is a hispanic catholic.\",     \"43 year old black female. Works as a social worker in Baltimore and is a practicing muslim.\"))      prompt <- \"I will give you demographic information. I want you to predict who they voted for in the 2020 Presidential election. Make your best guess if you are unsure. Say 'Trump' or 'Biden' only. Do not say anything else.\"  prompt2 <- \"I will give you demographic information. I want you to predict what political party they identify with or lean torwards. Make your best guess if you are unsure. Say 'Republican' or 'Democratic' only. Do not say anything else.\"  prompts <- c(prompt, prompt2) outputVec <- c(\"Vote\", \"Party\") sample_df <- gpt(sample_df, input = \"demo\", output = outputVec, prompt = prompts, model = \"gpt-3.5-turbo\", return_invisible = TRUE)  print(sample_df)"},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"another-example","dir":"","previous_headings":"","what":"Another Example","title":"AI Tools for R Datasets","text":"Let’s look another example. One AI tools can really shine - Textual Analysis! ask categorize statements either Pro-gun Anti-gun stances.","code":"messages <- data.frame(id = c(1, 2, 1),                         message = c(\"Guns are great\",                                     \"i think guns are bad\",                                     \"They protect my family and keep the king of england out of my face\"))  good <- \"I will give you a statement. I want you to tell me if the overall sentiment is 'Pro-gun' or 'Anti-gun'. Say 'Pro-gun' or 'Anti-gun' only.\"  messages <- gpt(messages, input = \"message\", output = \"GunStance\", prompt = good, model = \"gpt-3.5-turbo\", max_tokens = 5, return_invisible = TRUE)  View(messages)"},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"advanced-features","dir":"","previous_headings":"","what":"Advanced Features","title":"AI Tools for R Datasets","text":"Let’s look features haven’t talked yet. Sometimes just want run thing couple times just make sure. Perhaps asking Claude personally identifiable information certain field, maybe want Gemini deduce topic long comment. tasks multiple times good indication results internally valid. iterations argument comes . can pass iterations integer value function rerun call many times. add _X end output column iteration _2 second, _3 third, etc. can stack multiple prompts, thinking back Vote Party example also set iterations equal 2, run Vote Party twice. may noticed handy progress bar pops run functions. shows helpful information like number completed calls total number calls, estimated time remaining. like live suspense however, possible disable . Just set progress = FALSE. One useful arguments repair. special repair mode seeks solve common problems likely encounter. Perhaps get rate-limited trying run huge dataset , maybe OpenAI’s servers busy deny request. whatever reason error popping function finishes. Fret! Repair mode save day! Simply rerun function repair = TRUE, function pick right left . Repair mode works regardless return_invisible set True False (.e. can pass either dataframe llm_completion object) figure ! One caveat thought, progress bar isn’t yet compatible repair mode, won’t get see pretty bar inch across screen.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"AI Tools for R Datasets","text":"fully built R Package documentation available. ever want view documentation, just call ? function. give overview function detailed information argument function. switching model providers sure check defaults ranges various model parameters differ slightly model providers.","code":"?gpt ?claude ?gemini ?llm_generate ?list_models"},{"path":[]},{"path":"https://adam-hubbs.github.io/DBAI/reference/DBAI-package.html","id":null,"dir":"Reference","previous_headings":"","what":"DBAI: AI Tools for R Datasets — DBAI-package","title":"DBAI: AI Tools for R Datasets — DBAI-package","text":"R Wrapper AI API's. package designed make easier access use AI API's R. package designed used OpenAI API, Gemini API, Claude API.","code":""},{"path":[]},{"path":"https://adam-hubbs.github.io/DBAI/reference/DBAI-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"DBAI: AI Tools for R Datasets — DBAI-package","text":"Maintainer: Adam Hubbs amhubbs17@gmail.com","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/claude.html","id":null,"dir":"Reference","previous_headings":"","what":"claude — claude","title":"claude — claude","text":"claude","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/claude.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"claude — claude","text":"","code":"claude(   source,   input,   output = \"output\",   prompt,   model = \"claude-3-haiku-20240307\",   return_invisible = FALSE,   iterations = 1,   repair = FALSE,   progress = TRUE,   temperature = 1,   top_p = NULL,   top_k = NULL,   anthropic_version = \"2023-06-01\",   max_tokens = 4096,   anthropic_api_key = Sys.getenv(\"ANTHROPIC_API_KEY\") )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/claude.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"claude — claude","text":"source required; source dataframe llm-completion object. input required; column name source dataframe output optional; string column name (vector strings) created source dataframe storing output models. Defaults output. prompt required; string (vector Strings handling multiple operations time) system message sent AI model. model required; length one character vector. return_invisible optional; boolean return just output (TRUE) llm object containing model metadata (FALSE). Defaults FALSE. iterations optional; integer. Number completions generate row. Defaults 1. repair optional; boolean repair NA's output column keep values already present output column output column already created. False overrides data already output column exists. Useful continue computation rate limited. Defaults FALSE. progress optional; length one logical vector. Defaults TRUE. Determines whether show progress bar console. temperature optional; defaults 1; length one numeric vector value 0 (analytical) 1 (creative). top_p optional; length one numeric vector value 0 1. specify temperature top_p, never . recommended, use cases use temperature instead. top_k optional; length one numeric vector integer value greater 0. sample top_k options subsequent token. recommended, use cases use temperature instead. anthropic_version optional; defaults 2023-06-01; length one character vector. Specifies version Anthropic's models. max_tokens optional; defaults (4096 - prompt tokens); length one numeric vector integer value greater 0. anthropic_api_key required; defaults Sys.getenv(\"ANTHROPIC_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies Anthropic API key.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/claude.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"claude — claude","text":"dataframe output column(s) created","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gemini.html","id":null,"dir":"Reference","previous_headings":"","what":"gemini — gemini","title":"gemini — gemini","text":"gemini","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gemini.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gemini — gemini","text":"","code":"gemini(   source,   input,   output = \"output\",   prompt,   model = \"gemini-1.5-flash\",   return_invisible = FALSE,   iterations = 1,   repair = FALSE,   progress = TRUE,   temperature = 1,   top_p = NULL,   top_k = NULL,   max_tokens = 4096,   google_api_key = Sys.getenv(\"GOOGLE_API_KEY\") )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/gemini.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gemini — gemini","text":"source required; source dataframe llm-completion object. input required; column name source dataframe output optional; string column name (vector strings) created source dataframe storing output models. Defaults output. prompt required; string (vector Strings handling multiple operations time) prompts sent AI model. model required; length one character vector. return_invisible optional; boolean return just output (TRUE) llm-completion object containing model metadata (FALSE). Defaults FALSE. iterations optional; integer. Number completions generate prompt. Defaults 1. repair optional; boolean repair NA's output column keep values already present output column output column already created. False overrides data already output column exists. Useful continue computation rate limited. Defaults FALSE. progress optional; length one logical vector. Defaults TRUE. Determines whether show progress bar console. available using repair mode. temperature optional; defaults 1; length one numeric vector value 0 (analytical) 2 (creative). top_p optional; defaults 0.95; length one numeric vector value 0 1. top_k optional; length one numeric vector integer value greater 0. sample top_k options subsequent token. recommended, use cases use temperature instead. value provided, use nucleus sampling. max_tokens optional; length one numeric vector integer value greater 0. Gemini includes output tokens. Defaults 4096. google_api_key required; defaults Sys.getenv(\"GOOGLE_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies Google API key. Must obtain API Key Google.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gemini.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"gemini — gemini","text":"dataframe output column(s) created","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.character.html","id":null,"dir":"Reference","previous_headings":"","what":"gpt — gpt.character","title":"gpt — gpt.character","text":"gpt","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.character.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gpt — gpt.character","text":"","code":"# S3 method for class 'character' gpt(   source,   prompt = \"\",   progress = TRUE,   repair = FALSE,   iterations = 1,   model = \"gpt-3.5-turbo\",   temperature = 1,   top_p = 1,   n = 1,   presence_penalty = 0,   frequency_penalty = 0,   max_tokens = 4096,   openai_api_key = Sys.getenv(\"OPENAI_API_KEY\"),   openai_organization = NULL,   call = rlang::caller_env(),   output = \"output\",   suppress_line_messages = FALSE )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"gpt — gpt.data.frame","title":"gpt — gpt.data.frame","text":"gpt","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gpt — gpt.data.frame","text":"","code":"# S3 method for class 'data.frame' gpt(   source,   input,   output = \"output\",   prompt,   model = \"gpt-3.5-turbo\",   iterate_over = \"prompt\",   iterations = 1,   repair = FALSE,   progress = TRUE,   temperature = 1,   top_p = 1,   n = 1,   presence_penalty = 0,   frequency_penalty = 0,   max_tokens = 4096,   openai_api_key = Sys.getenv(\"OPENAI_API_KEY\"),   openai_organization = NULL )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gpt — gpt.data.frame","text":"source required; source dataframe llm-completion object. input required; column name source dataframe. output optional; string column name (vector strings) created source dataframe storing output models. Defaults output. prompt required; string (vector Strings handling multiple operations time) prompts sent AI model. model required; length one character vector. iterate_over optional; variable want iterate . Defaults prompt. iterations optional; integer. Number completions generate prompt Defaults 1. repair optional; boolean repair NA's output column keep values already present output column output column already created. False overrides data already output column exists. Useful continue computation rate limited. Defaults FALSE. progress optional; length one logical vector. Defaults TRUE. Determines whether show progress bar console. available using repair mode. temperature optional; defaults 1; length one numeric vector value 0 (analytical) 2 (creative). top_p optional; defaults 1; length one numeric vector value 0 1. n optional; defaults 1; length one numeric vector integer value greater 0. presence_penalty optional; defaults 0; length one numeric vector value -2 2. frequency_penalty optional; defaults 0; length one numeric vector value -2 2. max_tokens optional; defaults (4096 - prompt tokens); length one numeric vector integer value greater 0. openai_api_key required; defaults Sys.getenv(\"OPENAI_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies OpenAI API key. Must obtain API Key OpenAI. openai_organization optional; defaults NULL; length one character vector. Specifies OpenAI organization.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"gpt — gpt.data.frame","text":"dataframe output column(s) created","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.default.html","id":null,"dir":"Reference","previous_headings":"","what":"gpt — gpt.default","title":"gpt — gpt.default","text":"gpt","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gpt — gpt.default","text":"","code":"# Default S3 method gpt(   source,   input,   output = \"output\",   prompt,   model = \"gpt-3.5-turbo\",   return_invisible = FALSE,   iterations = 1,   repair = FALSE,   progress = TRUE,   temperature = 1,   top_p = 1,   n = 1,   presence_penalty = 0,   frequency_penalty = 0,   max_tokens = 4096,   openai_api_key = Sys.getenv(\"OPENAI_API_KEY\"),   openai_organization = NULL )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gpt — gpt.default","text":"source required; source dataframe llm-completion object. input required; column name source dataframe output optional; string column name (vector strings) created source dataframe storing output models. Defaults output. prompt required; string (vector Strings handling multiple operations time) prompts sent AI model. model required; length one character vector. return_invisible optional; boolean return just output (TRUE) llm-completion object containing model metadata (FALSE). Defaults FALSE. iterations optional; integer. Number completions generate prompt Defaults 1. repair optional; boolean repair NA's output column keep values already present output column output column already created. False overrides data already output column exists. Useful continue computation rate limited. Defaults FALSE. progress optional; length one logical vector. Defaults TRUE. Determines whether show progress bar console. available using repair mode. temperature optional; defaults 1; length one numeric vector value 0 (analytical) 2 (creative). top_p optional; defaults 1; length one numeric vector value 0 1. n optional; defaults 1; length one numeric vector integer value greater 0. presence_penalty optional; defaults 0; length one numeric vector value -2 2. frequency_penalty optional; defaults 0; length one numeric vector value -2 2. max_tokens optional; defaults (4096 - prompt tokens); length one numeric vector integer value greater 0. openai_api_key required; defaults Sys.getenv(\"OPENAI_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies OpenAI API key. Must obtain API Key OpenAI. openai_organization optional; defaults NULL; length one character vector. Specifies OpenAI organization.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"gpt — gpt.default","text":"dataframe output column(s) created","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.html","id":null,"dir":"Reference","previous_headings":"","what":"gpt — gpt","title":"gpt — gpt","text":"gpt","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gpt — gpt","text":"","code":"gpt(   source,   input,   output = \"output\",   prompt,   model = \"gpt-3.5-turbo\",   return_invisible = FALSE,   iterations = 1,   repair = FALSE,   progress = TRUE,   temperature = 1,   top_p = 1,   n = 1,   presence_penalty = 0,   frequency_penalty = 0,   max_tokens = 4096,   openai_api_key = Sys.getenv(\"OPENAI_API_KEY\"),   openai_organization = NULL,   call = rlang::caller_env() )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gpt — gpt","text":"source required; source dataframe llm-completion object. input required; column name source dataframe output optional; string column name (vector strings) created source dataframe storing output models. Defaults output. prompt required; string (vector Strings handling multiple operations time) prompts sent AI model. model required; length one character vector. return_invisible optional; boolean return just output (TRUE) llm-completion object containing model metadata (FALSE). Defaults FALSE. iterations optional; integer. Number completions generate prompt Defaults 1. repair optional; boolean repair NA's output column keep values already present output column output column already created. False overrides data already output column exists. Useful continue computation rate limited. Defaults FALSE. progress optional; length one logical vector. Defaults TRUE. Determines whether show progress bar console. available using repair mode. temperature optional; defaults 1; length one numeric vector value 0 (analytical) 2 (creative). top_p optional; defaults 1; length one numeric vector value 0 1. n optional; defaults 1; length one numeric vector integer value greater 0. presence_penalty optional; defaults 0; length one numeric vector value -2 2. frequency_penalty optional; defaults 0; length one numeric vector value -2 2. max_tokens optional; defaults (4096 - prompt tokens); length one numeric vector integer value greater 0. openai_api_key required; defaults Sys.getenv(\"OPENAI_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies OpenAI API key. Must obtain API Key OpenAI. openai_organization optional; defaults NULL; length one character vector. Specifies OpenAI organization.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/gpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"gpt — gpt","text":"dataframe output column(s) created","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/list_models.html","id":null,"dir":"Reference","previous_headings":"","what":"List models available in the OpenAI API (Anthropic has no API for this. Google does and support for Google will be added soon.) — list_models","title":"List models available in the OpenAI API (Anthropic has no API for this. Google does and support for Google will be added soon.) — list_models","text":"list_models","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/list_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List models available in the OpenAI API (Anthropic has no API for this. Google does and support for Google will be added soon.) — list_models","text":"","code":"list_models(openai_api_key = Sys.getenv(\"OPENAI_API_KEY\"))"},{"path":"https://adam-hubbs.github.io/DBAI/reference/list_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List models available in the OpenAI API (Anthropic has no API for this. Google does and support for Google will be added soon.) — list_models","text":"openai_api_key required; defaults Sys.getenv(\"OPENAI_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies OpenAI API key.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/list_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List models available in the OpenAI API (Anthropic has no API for this. Google does and support for Google will be added soon.) — list_models","text":"list models available OpenAI API.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/llm_generate.html","id":null,"dir":"Reference","previous_headings":"","what":"llm_generate — llm_generate","title":"llm_generate — llm_generate","text":"llm_generate","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/llm_generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"llm_generate — llm_generate","text":"","code":"llm_generate(   source,   input,   output = \"output\",   prompt,   model = \"gpt-3.5-turbo\",   return_invisible = FALSE,   iterations = 1,   repair = FALSE,   progress = TRUE,   temperature = 1,   top_p = 1,   top_k = NULL,   anthropic_version = \"2023-06-01\",   n = 1,   presence_penalty = 0,   frequency_penalty = 0,   max_tokens = 4096,   openai_api_key = Sys.getenv(\"OPENAI_API_KEY\"),   openai_organization = NULL,   anthropic_api_key = Sys.getenv(\"ANTHROPIC_API_KEY\"),   google_api_key = Sys.getenv(\"GOOGLE_API_KEY\") )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/llm_generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"llm_generate — llm_generate","text":"source required; source dataframe llm-completion object. input required; column name source dataframe output optional; string column name (vector strings) created source dataframe storing output models. Defaults output. prompt required; string (vector Strings handling multiple operations time) prompts sent AI model. model required; character vector. return_invisible optional; boolean return just output (TRUE) llm-completion object containing model metadata (FALSE). Defaults FALSE. iterations optional; integer. Number completions generate prompt Defaults 1. repair optional; boolean repair NA's output column keep values already present output column output column already created. False overrides data already output column exists. Useful continue computation rate limited. Defaults FALSE. progress optional; length one logical vector. Defaults TRUE. Determines whether show progress bar console. available using repair mode. temperature optional; defaults 1; length one numeric vector value 0 (analytical) 2 (creative). 0-2 OpenAI Google models, 0-1 Anthropic models. top_p optional; defaults 1; numeric vector value 0 1. top_k optional; numeric vector integer value greater 0. sample top_k options subsequent token. recommended, use cases use temperature instead. anthropic_version optional; defaults 2023-06-01; character vector. Specifies version Anthropic's models. n optional; defaults 1; numeric vector integer value greater 0. presence_penalty optional; defaults 0; numeric vector value -2 2. frequency_penalty optional; defaults 0; numeric vector value -2 2. max_tokens optional; defaults (4096 - prompt tokens); numeric vector integer value greater 0. openai_api_key optional; defaults Sys.getenv(\"OPENAI_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies OpenAI API key. Must obtain API Key OpenAI. openai_organization optional; defaults NULL; length one character vector. Specifies OpenAI organization. anthropic_api_key optional; defaults Sys.getenv(\"ANTHROPIC_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies Anthropic API key. google_api_key optional; defaults Sys.getenv(\"GOOGLE_API_KEY\") (.e., value retrieved .Renviron file); length one character vector. Specifies Google API key. Must obtain API Key Google.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/llm_generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"llm_generate — llm_generate","text":"dataframe output column(s) created","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/match.call.defaults.html","id":null,"dir":"Reference","previous_headings":"","what":"Match.Call.Defaults — match.call.defaults","title":"Match.Call.Defaults — match.call.defaults","text":"Match.Call.Defaults","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/match.call.defaults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match.Call.Defaults — match.call.defaults","text":"","code":"match.call.defaults(...)"},{"path":"https://adam-hubbs.github.io/DBAI/reference/match.call.defaults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match.Call.Defaults — match.call.defaults","text":"...","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/match.call.defaults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match.Call.Defaults — match.call.defaults","text":"Call function default values filled .","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/new_llm_completion.html","id":null,"dir":"Reference","previous_headings":"","what":"new_llm_completion — new_llm_completion","title":"new_llm_completion — new_llm_completion","text":"new_llm_completion","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/new_llm_completion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"new_llm_completion — new_llm_completion","text":"","code":"new_llm_completion(   x = character(),   Call = NULL,   Prompt = NULL,   Model = NULL,   Model_Provider = NULL,   Date = NULL,   Temperature = NULL,   Raw = NULL )"},{"path":"https://adam-hubbs.github.io/DBAI/reference/new_llm_completion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"new_llm_completion — new_llm_completion","text":"x vector made new llm_completion object Prompt prompt used generate completion Model model used generate completion Model_Provider provider model used generate completion Date date completion generated Temperature temperature used generate completion Raw sample raw completion data","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/new_llm_completion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"new_llm_completion — new_llm_completion","text":"new llm_completion object","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/print.llm_completion_DBAI.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for llm_completion objects — print.llm_completion_DBAI","title":"Print Method for llm_completion objects — print.llm_completion_DBAI","text":"Print Method llm_completion objects","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/print.llm_completion_DBAI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for llm_completion objects — print.llm_completion_DBAI","text":"","code":"# S3 method for class 'llm_completion_DBAI' print(x, ...)"},{"path":"https://adam-hubbs.github.io/DBAI/reference/print.llm_completion_DBAI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for llm_completion objects — print.llm_completion_DBAI","text":"x llm_completion object printed. ... optional. arguments passed print method.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/print.llm_completion_DBAI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for llm_completion objects — print.llm_completion_DBAI","text":"invisible","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/summary.llm_completion_DBAI.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for llm_completion objects — summary.llm_completion_DBAI","title":"Summary Method for llm_completion objects — summary.llm_completion_DBAI","text":"Summary Method llm_completion objects","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/summary.llm_completion_DBAI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for llm_completion objects — summary.llm_completion_DBAI","text":"","code":"# S3 method for class 'llm_completion_DBAI' summary(x, ...)"},{"path":"https://adam-hubbs.github.io/DBAI/reference/summary.llm_completion_DBAI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for llm_completion objects — summary.llm_completion_DBAI","text":"x llm_completion object summarized. ... optional. arguments passed print method.","code":""},{"path":"https://adam-hubbs.github.io/DBAI/reference/summary.llm_completion_DBAI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for llm_completion objects — summary.llm_completion_DBAI","text":"invisible","code":""},{"path":[]},{"path":"https://adam-hubbs.github.io/DBAI/news/index.html","id":"documentation-update-development-version","dir":"Changelog","previous_headings":"","what":"Documentation Update","title":"DBAI (development version)","text":"Github Pages News updated","code":""}]
