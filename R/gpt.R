
#' gpt
#'
#' @param source A source dataframe
#' @param input A column name in the source dataframe
#' @param output A string of a column name (Or a vetor of strings) to be created in the source dataframe.
#' @param systemMessage A string (Or vector of Strings for handling multiple operations at the same time) of a system message to be sent to the GPT model
#' @param model The OpenAI Model to be called
#' @param temperature Temperature parameter for OpenAI's models
#' @param top_p top_p parameter for OpenAI's models
#' @param max_tokens Maximum tokens to be generated by OpenAI's models
#' @param ...
#'
#' @return A dataframe with the output column(s) created
#' @export
#'
#' @examples
#' sample_df <- gpt(sample_df, input = "demo", output = "Vote", systemMessage = prompt, model = "gpt-3.5-turbo", max_tokens = 5)
gpt <- function(source,
                input = "input",
                output = "output",
                systemMessage,
                model = "gpt-3.5-turbo",
                temperature = 1,
                top_p = NULL,
                max_tokens = 4096,  ...) {


  ### Validate Statements
  assert_that(!is.null(source), msg = "Dataframe is null. Please provide a dataframe.")
  assert_that(nrow(source) > 0, msg = "Dataframe is empty. Please provide a valid dataframe.")
  assert_that(is.data.frame(source) || is_tibble(source), msg = "Input 'source' must be a dataframe or tibble.")
  assert_that(is.character(model) && (length(model) == 1), msg = "Model must be text.")



  CallGPT <- function(input, output, systemMessage, model = model, temperature, n=1, max_tokens=4096, ...) {
    ### Do not quit if there are NA's, just return NA for those rows
    if(is.na(input)) {
      warning("There are NA's in the input column. NA's introduced in the output.")
      return(NA)
    } else {
      ### Call to OpenAI Endpoint
      create_chat_completion(
        model = model,
        n = n,
        max_tokens = max_tokens,
        temperature = temperature,
        messages = list(
          list(
            "role" = "system",
            "content" = systemMessage
          ),
          list(
            "role" = "user",
            "content" = input
          )
        )
      )$choices$message.content
    }
  }

  ### Loops Oupuut Columns to run Vectorized GPT Calls
  for (h in c(1:length(systemMessage))) {
    source <- source |>
      mutate(!!output[h] := lapply(source[[input]], CallGPT, systemMessage = systemMessage[h], model = model, temperature = temperature, max_tokens = max_tokens))
  }
  return(source)
}
